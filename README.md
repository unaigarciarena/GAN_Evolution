# GAN_Evolution

The initial version of this proyect contains the code developed for the experimental part of the following paper:

Garciarena, U., Santana, R., & Mendiburu, A. (2018, July). Evolved GANs for generating Pareto set approximations. In Proceedings of the Genetic and Evolutionary Computation Conference (pp. 434-441). ACM.

It has been improved since, adding more loss functions, reducing the number of networks that produced NaN values, and correcting some errors in variable scaling. For running the code, execute the following line:

python3 GAN_Descriptor_Deap.py <seed> <points> <variables> <function> <z_size> <n_layers> <loop> <n_neurons> <pop_size> <n_gen> <sel_tipe> <cross> <sel_size>
  
where 

 <points> are the number of points used to train the GANs and the number of points generated by the GANs (1000 in the paper)
  
 <variables> is the number of decision variables used in the problem (10 or 784)
  
 <function> is the function used for evolving the GAN ([1, 2, 3, 4, 5, 7, 8, 9])
  
 <z_size> is the size of the latent variable (30)

 <n_layers> is the depth limit of the evolved networks (10)

 <loop> is the limit of times each network can be trained with a batch in a single iteration (5)

 <n_neurons> is the limit of neurons in each layer in the evolved networks (50)

 <pop_size> is the number of GANs in each population (20)

 <n_gen> is the number of generations used for evolution (500)

 <sel_type> is the selection method between generations (2, NSGA)

 <cross> crossover probability (90)

 <sel_size> number of elements selected from the previous population to advance (10)
